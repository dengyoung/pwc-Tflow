

import sys
import os
import torch
import cv2
import numpy as np



class E2EFlowBase:
    """
    Base class for E2E flow computation
    """
    def __init__(self, height, width, fov_x_half_tan):
        self.height = height
        self.width = width
        self.fov_x_half_tan = fov_x_half_tan
        self.fov_y_half_tan = fov_x_half_tan * height / width
        
        self.mock_img = None
        self.prev_img = None
        self.cur_img = None
        self.match_img = None
        
    def coords_grid(self, h, w):
        ys, xs = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')  # [H, W]
        stacks = [xs, ys]
        grid = np.stack(stacks, axis=0).astype(np.float32)  # [2, H, W] or [3, H, W]
        # grid = np.tile(grid[None], (b, 1, 1, 1))  # [B, 2, H, W] or [B, 3, H, W]
        # print('grid', grid.shape)
        return grid
    
    def flow_warp_np(self, feature, flow):
        """warp feature using flow; feature is src image, 
        grid + flow -> warped grid(in feature image)
        
        Args:
            feature (np.ndarray): feature or image
            flow (np.ndarray): flow

        Returns:
            np.ndarray: warped feature
        """
        # c, h, w = feature.shape
        h, w, c = feature.shape
        grid = self.coords_grid(h, w) + flow  # [2, H, W]
        grid = grid.transpose(1, 2, 0)
        warp_feature = cv2.remap(feature, grid, None, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
        return warp_feature
    
    def get_deltaR_flow(self, R_old:np.ndarray=None, R:np.ndarray=None, delta_R=None)->np.ndarray:
        """flow using mock image, generated by (current R - last R), old image based

        Args:
            R_old (np.ndarray): R_old
            R (np.ndarray): R
            delta_R: R_old.T @ R TO CHECK!!!

        Returns:
            np.ndarray: flow_R
        """
        if delta_R is not None:
            R_old = np.eye(3)
            R = delta_R
        
        
        mock_depth = np.ones((self.height, self.width)) * 1.0
        mock_p = [0.0, 0.0, 0.0]
        flow_R = self.get_gt_flow_by_prev_depth(prev_depth=mock_depth, p=mock_p, R=R, p_old=mock_p, R_old=R_old)
        
        return flow_R

    # def get_deltaR_coords_flow(self, coords, R_old, R, delta_R=None)->np.ndarray:
    #     if delta_R is not None:
    #         R_old = np.eye(3)
    #         R = delta_R
        
    #     # coords shape (2, H, W)
    #     # fake point cloud
    #     pix_v, pix_u = coords
    #     height, width = pix_v.shape
    #     flow_gt = np.zeros((2, height, width), dtype=np.float32)
        
    #     cam_fv = self.fov_x_half_tan * 2 / width * (pix_v+ 0.5) - self.fov_x_half_tan - 1e-5
    #     cam_fu = self.fov_y_half_tan * 2 / height * (pix_u+ 0.5) - self.fov_y_half_tan - 1e-5
        
    #     dx = R_old[0][0] - cam_fu * R_old[0][2] - cam_fv * R_old[0][1]
    #     dy = R_old[1][0] - cam_fu * R_old[1][2] - cam_fv * R_old[1][1]
    #     dz = R_old[2][0] - cam_fu * R_old[2][2] - cam_fv * R_old[2][1]
        
    #     ptx = dx 
    #     pty = dy
    #     ptz = dz 
        
    #     fz_cur = ptx * R[0][0] + pty * R[1][0] + ptz * R[2][0]
        
    #     fu_cur = (-ptx * R[0][2] - pty * R[1][2] - ptz * R[2][2]) / fz_cur
    #     fv_cur = (-ptx * R[0][1] - pty * R[1][1] - ptz * R[2][1]) / fz_cur
    #     u_cur = ((fu_cur + 1e-5) / self.fov_y_half_tan + 1) / 2 * height  - 0.5
    #     v_cur = ((fv_cur + 1e-5) / self.fov_x_half_tan + 1) / 2 * width  - 0.5

    #     delta_v = v_cur - pix_v
    #     # delta_v[np.abs(delta_v) > 40.0] = 0.0

    #     delta_u = u_cur - pix_u
        
    #     flow_gt[0] = np.where(fz_cur > 0.1, delta_v, .0) 
    #     flow_gt[1] = np.where(fz_cur > 0.1, delta_u, .0) 
    #     return flow_gt
        

    def get_gt_flow_by_prev_depth(self, prev_depth, p, R, p_old, R_old, coords=None, clip_depth=-1)->np.ndarray:
        """render opti_ground truth using prev_depth, no batch

        Args:
            prev_depth (np.ndarray): previous depth img
            p (ndarray): current position
            R (ndarray): current R
            p_old (ndarray): last position
            R_old (ndarray): last R
            coords: corresponding to depth, can handle flow middle state. it is like warped coords
            clip_depth (int, optional): clip depth value. Defaults to -1.

        Returns:
            np.ndarray: flow_gt
        """
        if clip_depth > 0:
            prev_depth[prev_depth > clip_depth] = 1000
        
        # print('prev_depth', prev_depth.shape)
        height, width = prev_depth.shape
        
        flow_gt = np.zeros((2, height, width), dtype=np.float32)

        if coords is not None:
            pix_v, pix_u = coords
        
        else:
            pix_v, pix_u = np.meshgrid(np.linspace(0, width - 1, width), np.linspace(0, height - 1, height))
        # cam_fv cam_fu w*h
        cam_fv = self.fov_x_half_tan * 2 / width * (pix_v + 0.5) - self.fov_x_half_tan - 1e-5
        cam_fu = self.fov_y_half_tan * 2 / height * (pix_u + 0.5) - self.fov_y_half_tan - 1e-5

        dx = R_old[0][0] - cam_fu * R_old[0][2] - cam_fv * R_old[0][1]
        dy = R_old[1][0] - cam_fu * R_old[1][2] - cam_fv * R_old[1][1]
        dz = R_old[2][0] - cam_fu * R_old[2][2] - cam_fv * R_old[2][1]


        ptx = p_old[0] + dx * prev_depth - p[0]
        pty = p_old[1] + dy * prev_depth - p[1]
        ptz = p_old[2] + dz * prev_depth - p[2]

        fz_cur = ptx * R[0][0] + pty * R[1][0] + ptz * R[2][0]
        
        fu_cur = (-ptx * R[0][2] - pty * R[1][2] - ptz * R[2][2]) / fz_cur
        fv_cur = (-ptx * R[0][1] - pty * R[1][1] - ptz * R[2][1]) / fz_cur
        u_cur = ((fu_cur + 1e-5) / self.fov_y_half_tan + 1) / 2 * height - 0.5
        v_cur = ((fv_cur + 1e-5) / self.fov_x_half_tan + 1) / 2 * width - 0.5

        delta_v = v_cur - pix_v
        # delta_v[np.abs(delta_v) > 40.0] = 0.0

        delta_u = u_cur - pix_u
        # delta_u[np.abs(delta_u) > 40.0] = 0.0
        flow_gt[0] = np.where(fz_cur > 0.1, delta_v, .0) 
        flow_gt[1] = np.where(fz_cur > 0.1, delta_u, .0) 

        # flow_gt[0] = np.where(fz_old > 0.1, delta_v, .0)
        # flow_gt[1] = np.where(fz_old > 0.1, delta_u, .0) 

        # print('new method ', flow_gt[1][96][128])
        #flow gt shape (2, 192, 256)
        return flow_gt
    
    def get_gt_flow_by_cur_depth(self, cur_depth, p, R, p_old:np.ndarray, R_old:np.ndarray, clip_depth=-1)->np.ndarray:
        """render flow gt using depth, no batch, R should contain cam_angle
        # Watchout To Remain the same 
        '''
        —————— v
        |
        |
        |
        u
        '''

        Args:
            cur_depth (np.ndarray): current depth img
            p (np.ndarray): current position
            R (np.ndarray): current R
            p_old (np.ndarray): last position
            R_old (np.ndarray): last R
            clip_depth (int, optional): clip depth value. Defaults to -1.

        Returns:
            np.ndarray: flow_gt
        """
        if clip_depth > 0:
            cur_depth[cur_depth > clip_depth] = 1000
        
        height, width = cur_depth.shape
        
        flow_gt = np.zeros((2, height, width), dtype=np.float32)
  
        pix_v, pix_u = np.meshgrid(np.linspace(0, width - 1, width), np.linspace(0, height - 1, height))
        # cam_fv cam_fu w*h
        cam_fv = self.fov_x_half_tan * 2 / width * (pix_v + 0.5) - self.fov_x_half_tan - 1e-5
        cam_fu = self.fov_y_half_tan * 2 / height * (pix_u + 0.5) - self.fov_y_half_tan - 1e-5

        dx = R[0][0] - cam_fu * R[0][2] - cam_fv * R[0][1]
        dy = R[1][0] - cam_fu * R[1][2] - cam_fv * R[1][1]
        dz = R[2][0] - cam_fu * R[2][2] - cam_fv * R[2][1]


        ptx = p[0] + dx * cur_depth - p_old[0]
        pty = p[1] + dy * cur_depth - p_old[1]
        ptz = p[2] + dz * cur_depth - p_old[2]

        fz_old = ptx * R_old[0][0] + pty * R_old[1][0] + ptz * R_old[2][0]
        
        fu_old = (-ptx * R_old[0][2] - pty * R_old[1][2] - ptz * R_old[2][2]) / fz_old
        fv_old = (-ptx * R_old[0][1] - pty * R_old[1][1] - ptz * R_old[2][1]) / fz_old
        u_old = ((fu_old + 1e-5) / self.fov_y_half_tan + 1) / 2 * height - 0.5
        v_old = ((fv_old + 1e-5) / self.fov_x_half_tan + 1) / 2 * width - 0.5

        delta_v = pix_v - v_old
        # delta_v[np.abs(delta_v) > 40.0] = 0.0

        delta_u = pix_u - u_old
        # delta_u[np.abs(delta_u) > 40.0] = 0.0
        flow_gt[0] = np.where(fz_old > 0.1, delta_v, .0) 
        flow_gt[1] = np.where(fz_old > 0.1, delta_u, .0) 

        # flow_gt[0] = np.where(fz_old > 0.1, delta_v, .0)
        # flow_gt[1] = np.where(fz_old > 0.1, delta_u, .0) 

        # print('new method ', flow_gt[1][96][128])
        #flow gt shape (2, 192, 256)
        return flow_gt
    
    
    def flow_to_color(self, flow:np.ndarray):
        """coloring flow

        Args:
            flow (np.ndarray): input ndarray (2, height, width)

        Returns:
            np.ndarray: cv2:numpy array
        """
        h, w = flow.shape[1:]
        mag, ang = cv2.cartToPolar(flow[0], flow[1])
        hsv = np.zeros((h, w, 3), dtype=np.float32)
        hsv[..., 0] = ang * 180 / np.pi / 2
        hsv[..., 1] = np.clip(51 * mag, 0, 255)
        hsv[..., 2] = 255
        return cv2.cvtColor(hsv.astype('uint8'), cv2.COLOR_HSV2BGR)
    
    
    def draw_flow_on_src(self, flow:np.ndarray, old_img:np.ndarray, cur_img:np.ndarray, mask=None)->np.ndarray:
        """draw match on src image, cur img based method

        Args:
            flow (np.ndarray): cur_uv - old_uv, based on cur_img, 2*H*W
            old_img (np.ndarray): old_img, H*W*3
            cur_img (np.ndarray): cur_img, H*W*3
            mask (np.ndarray, optional):  point index mask, same shape with img. Defaults to None.

        Returns:
            nd_array: cat_nd_array
        """
        if mask is None:
            mask = np.zeros_like(flow[0])
            mask[0:-1:25, 0:-1:25] = 1

        if flow is None or old_img is None or cur_img is None:
            return np.zeros((self.height*2, self.width*2, 3), dtype=np.uint8)
        
        # depth image 
        if old_img.ndim == 2:
            old_img = np.repeat(old_img[..., None], 3, axis=-1)
            cur_img = np.repeat(cur_img[..., None], 3, axis=-1)

        h, w = flow.shape[1:]
        # right up and left down  black area
        blank_ru = np.zeros((h, w, 3), dtype=np.uint8)
        blank_ld = np.zeros((h, w, 3), dtype=np.uint8)

        # up->old image; down->cur image
        cat_img_up = np.concatenate([old_img, blank_ru], axis=1)
        cat_img_down = np.concatenate([blank_ld, cur_img], axis=1)
        cat_img = np.concatenate([cat_img_up, cat_img_down], axis=0)
        

        # cur img based
    
        h_u, w_v = np.nonzero(mask)
        for u, v in zip(h_u, w_v):
            cv2.line(cat_img, (w + v, h + u), (int(v - flow[0][u][v]), int(u - flow[1][u][v])), (0, 255, 0))
            cv2.circle(cat_img, (w + v, h + u), 1, (255, 0, 0), -1)
            cv2.circle(cat_img, (int(v - flow[0][u][v]), int(u - flow[1][u][v])), 1, (255, 0, 0), -1)       
            
        return cat_img
    
    def draw_old_based_flow_on_src(self, flow:np.ndarray, old_img:np.ndarray, cur_img:np.ndarray, mask=None)->np.ndarray:
        """draw match on src image

        Args:
            flow is old_based
            flow (np.ndarray): cur_uv - old_uv
            old_img (np.ndarray): old_img
            cur_img (np.ndarray): cur_img
            downsample (int, optional): downsample match point to draw. Defaults to 20.
            u_idx (_type_, optional): if use certain idx. Defaults to None.
            v_idx (_type_, optional): if use certain idx. Defaults to None.

        Returns:
            nd_array: cat_nd_array
        """
        

        if flow is None or old_img is None or cur_img is None:
            return np.zeros((self.height*2, self.width*2, 3), dtype=np.uint8)
        
        if mask is None:
            mask = np.zeros_like(flow[0])
            mask[0:-1:25, 0:-1:25] = 1
        
        if old_img.ndim == 2:
            old_img = np.repeat(old_img[..., None], 3, axis=-1)
            cur_img = np.repeat(cur_img[..., None], 3, axis=-1)
        h, w = flow.shape[1:]
        # right up and left down  black area
        blank_ru = np.zeros((h, w, 3), dtype=np.uint8)
        blank_ld = np.zeros((h, w, 3), dtype=np.uint8)

        # up->old image; down->cur image
        cat_img_up = np.concatenate([old_img, blank_ru], axis=1)
        cat_img_down = np.concatenate([blank_ld, cur_img], axis=1)
        cat_img = np.concatenate([cat_img_up, cat_img_down], axis=0)
        
     
        # note here base is old image, should not abuse
   
        h_u, w_v = np.nonzero(mask)
        for u, v in zip(h_u, w_v):
            cv2.line(cat_img, (v, u), (int(w + v + flow[0][u][v]), int(h + u + flow[1][u][v])), (0, 255, 0))
            cv2.circle(cat_img, (v, u), 1, (255, 0, 0), -1)
            cv2.circle(cat_img, (int(w + v + flow[0][u][v]), int(h + u + flow[1][u][v])), 1, (255, 0, 0), -1)         
            
        return cat_img
    
    def get_nn_flow(self, img1:np.ndarray, img2:np.ndarray)->np.ndarray:
        raise NotImplementedError
    
    def get_epe_error(self, flow_gt:np.ndarray, flow:np.ndarray)->np.ndarray:
        """get end point error

        Args:
            flow_gt (np.ndarray): ground truth flow
            flow (np.ndarray): predicted flow

        Returns:
            np.ndarray: epe error
        """
        epe = np.sqrt(np.sum((flow_gt - flow)**2, axis=0))
        return epe.mean()
    
    def resize_flow(self, flow:np.ndarray, size:tuple)->np.ndarray:
        """resize flow

        Args:
            flow (np.ndarray): flow
            size (tuple): size, (h, w)

        Returns:
            np.ndarray: resized flow
        """
        h, w = size
        flow = cv2.resize(flow.transpose(1, 2, 0), (w, h)).transpose(2, 0, 1)
        return flow
    
    
    def get_flow_with_R_warping(self, img1:np.ndarray, img2:np.ndarray, R=None, R_old=None)->np.ndarray:
        """get flow with R warping first +  nn flow

        Args:
            img1 (np.ndarray): raw numpy img (height,width,3)
            img2 (np.ndarray): raw numpy img (height,width,3)
            R (_type_, optional): R. Defaults to None.
            R_old (_type_, optional): R. Defaults to None.

        Returns:
            np.ndarray: _description_
        """
        
        # flow_R = self.get_deltaR_flow(R_old, R)
        # warping_img1 = self.flow_warp_np(img1, flow_R)
        # neu_flow = self.get_nn_flow(warping_img1, img2)
        # flow = flow_R + neu_flow
        
        flow_R = self.get_deltaR_flow(R_old=R, R=R_old)
        warping_img2 = self.flow_warp_np(img2, flow_R)
        neu_flow = self.get_nn_flow(img1, warping_img2)
        flow = -flow_R + neu_flow
        return flow
    
    def get_middle_coord_grid(self, h:int, w:int, local_size=(120, 160))->np.ndarray:
        """_summary_
        ----xs
        |
        |
        ys
        
        Args:
            h (int): h
            w (int): w
            local_size (tuple (h, w), optional): local_size. Defaults to (120, 160).

        Returns:
            _type_: _description_
        """
        middle_h = local_size[0] 
        middle_w = local_size[1] 
        h_start = (h  - middle_h) // 2
        w_start = (w  - middle_w) // 2
        h_end = h_start + middle_h
        w_end = w_start + middle_w
        
        ys, xs = np.meshgrid(np.arange(h_start, h_end), np.arange(w_start, w_end), indexing='ij')  # [H, W]
        stacks = [xs, ys]
        grid = np.stack(stacks, axis=0).astype(np.float32)
        
        # print('ys', ys)
        return h_start, w_start, grid
    
    def get_local_iterative_flow(self, img1:np.ndarray, img2:np.ndarray, flow:np.ndarray, local_size=(120, 160)):
        """iteratively generate flow based on previous flow

        Args:
            img1 (np.ndarray): rgb_prev
            img2 (np.ndarray): rgb_cur
            flow (np.ndarray): _description_
            local_size (tuple, optional): _description_. Defaults to (120, 160).
        """
        
        h, w = img1.shape[:2]
        assert h >= local_size[0] and w >= local_size[1]
        h_scale = local_size[0] / h
        w_scale = local_size[1] / w
        
        # warp first + resize after
        h_start, w_start, middle_grid = self.get_middle_coord_grid(h, w, local_size)
        # middle flow shape (2, (local_size))
        middle_flow = flow[:, h_start:h_start + local_size[0], w_start:w_start + local_size[1]]
        middle_warp_target = middle_grid + middle_flow
        middle_warp_target = middle_warp_target.transpose(1, 2, 0)
        rgb_cur_warp_back = cv2.remap(img2, middle_warp_target, None, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
        
        rgb_prev_middle = img1[h_start:h_start + local_size[0], w_start:w_start + local_size[1]]
        rgb_prev_resized = cv2.resize(rgb_prev_middle, (w, h))
        
        # print('rgb_prev_resized', rgb_prev_resized.shape)
        
        rgb_cur_warped_resized = cv2.resize(rgb_cur_warp_back, (w, h))
        # print('rgb_cur_warped_resized', rgb_cur_warped_resized.shape)
        
        
        
        # get middle area flow
        
        middle_fullsize_flow = self.get_nn_flow(rgb_prev_resized, rgb_cur_warped_resized)
        middle_fullsize_flow_vis = self.flow_to_color(middle_fullsize_flow)
        
        
        raw_flow_vis = self.flow_to_color(flow)
        
        
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512raw_flow.png', raw_flow_vis)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512rgb_prev.png', img1)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512rgb_prev_resized.png', rgb_prev_resized)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512rgb_cur_warped_resized.png', rgb_cur_warped_resized)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512middle_resized_flow.png', middle_resized_flow_vis)
        # refined_fullsize_flow = cv2.resize(middle_flow.transpose(1, 2, 0), (w, h)).transpose(2, 0, 1) / scale + middle_resized_flow
        # refined_fullsize_flow_vis = self.flow_to_color(refined_fullsize_flow)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512refined_fullsize_flow.png', refined_fullsize_flow_vis)
        
        middle_fullsize_flow = middle_fullsize_flow.transpose(1, 2, 0)
        middle_localsize_flow = cv2.resize(middle_fullsize_flow, (local_size[1], local_size[0])).transpose(2, 0, 1)
        middle_localsize_flow[0] = middle_localsize_flow[0] * w_scale
        middle_localsize_flow[1] = middle_localsize_flow[1] * h_scale
        
        refined_flow = middle_localsize_flow + middle_flow
        
            
        # refined_flow_vis = self.flow_to_color(refined_flow)
        # cv2.imwrite('/home/henryhuyu/SciRobotic/e2e_planner_v1/HITL_exps/middle_iterative_warping/384x512refined_flow.png', refined_flow_vis)
        
        # refined flow size = local_size
        return refined_flow
        
        
        
if __name__ == '__main__':
    e2e_flow = E2EFlowBase(192, 256, 0.5)
    # e2e_flow.get_middle_coord_grid(192, 256)
    
    theta = np.deg2rad(10)
    delta_R = np.array([
        [np.cos(theta), -np.sin(theta), 0],
        [np.sin(theta), np.cos(theta), 0],
        [0, 0, 1]
    ])
    
    # e2e_flow.get_deltaR_flow(delta_R=delta_R)
    coords = e2e_flow.coords_grid(3, 4)
    print('coords', coords)
    pass   
        
   